{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pointed-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:mysql.connector.connection:new_auth_plugin: mysql_native_password\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nifty_fmcg', 'nifty_auto']\n",
      "Current Time = 12:15:14\n"
     ]
    }
   ],
   "source": [
    "%run /home/ec2-user/trading/Data/cloud_database_connector.ipynb\n",
    "import requests\n",
    "from kiteconnect import KiteConnect\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pypfopt import HRPOpt\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "import pytz\n",
    "import json\n",
    "from datetime import datetime\n",
    "# getting utc timezone\n",
    "utc = pytz.utc\n",
    "# getting timezone by name\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "# getting datetime of specified timezone\n",
    "now = datetime.now(tz=ist)\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wrapped-maldives",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://kite.trade/connect/login?api_key=wdpetlyn5mejtks1&v=3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Connect to Data Feed #######\n",
    "##################\n",
    "kite = KiteConnect(api_key = \"wdpetlyn5mejtks1\") \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "kite.login_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "damaged-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"POST /session/token HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "data = kite.generate_session(\"u5jinaKQM4kmpZrYdn8O2VMu1hbkLGua\", api_secret=\"lgb409rqfl8wpx308s2485v4r16fesic\")\n",
    "kite.set_access_token(data[\"access_token\"])\n",
    "token = data[\"access_token\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "owned-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /instruments/NSE HTTP/1.1\" 200 60150\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): masterswift.mastertrust.co.in:443\n",
      "DEBUG:urllib3.connectionpool:https://masterswift.mastertrust.co.in:443 \"GET /api/v2/contracts.json?exchanges=NSE HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "############ Fetch Symbols and Respective Tokens From Zerodha ###############\n",
    "instrument_dump = kite.instruments(\"NSE\")\n",
    "def instrumentLookup(symbol):\n",
    "    instrument_df = pd.DataFrame(instrument_dump)\n",
    "    \"\"\"Looks up instrument token for a given script from instrument dump\"\"\"\n",
    "    try:\n",
    "        return instrument_df[instrument_df.tradingsymbol==symbol].instrument_token.values[0]\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "j = requests.get(url=\"https://masterswift.mastertrust.co.in/api/v2/contracts.json?exchanges=NSE\")\n",
    "\n",
    "# looks to be json so let's see if json will load it\n",
    "content = json.loads(j.content)\n",
    "mt_df = pd.DataFrame.from_dict(content['NSE'])\n",
    "\n",
    "\n",
    "df = pd.read_csv('nifty50.csv')\n",
    "symbolist = []\n",
    "for sym in df.Symbol:\n",
    "    symbolist.append(sym)\n",
    "    \n",
    "symbolist = sorted(symbolist)\n",
    "token_list = [] \n",
    "for symbol in symbolist:\n",
    "    token_list.append(instrumentLookup(symbol))\n",
    "    \n",
    "token_map = {}\n",
    "for tok,sym in zip(token_list, symbolist):\n",
    "    token_map.update({sym.upper() + '-EQ':tok})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### Form A Symbolist and Tokenlist #################################################################\n",
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "month = dt.strftime(\"%B\")\n",
    "def get_trading_symbols():\n",
    "    futureslist = []\n",
    "    for tick in tickdatalist:\n",
    "        if \"21APRFUT\" in tick:\n",
    "            futureslist.append(tick) ### get the front month symbols\n",
    "            \n",
    "    ###### Get the your securities universe #####\n",
    "    df = pd.read_csv('/home/ec2-user/trading/Trade/nifty50.csv')\n",
    "    cashlist  = []\n",
    "    for sym in df.Symbol:\n",
    "        cashlist.append(sym)\n",
    "    #print(cashlist)\n",
    "    equity_fut =  []\n",
    "    for cash in cashlist:\n",
    "        fut_sym = cash + \"21APRFUT\"\n",
    "        equity_fut.append(fut_sym)\n",
    "        \n",
    "    #print(equity_fut)\n",
    "    \n",
    "    currency_fut = ['USDINR21APRFUT', 'EURINR21APRFUT','GBPINR21APRFUT','JPYINR21APRFUT']\n",
    "    com_list= ['GOLD', 'CRUDE', \"NATURALGAS\",\"SILVER\"]\n",
    "    \n",
    "    \n",
    "    return cashlist #+ equity_fut\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unexpected-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def format_response_filter1(predict_string):\n",
    "    print(\"Entering Format_response\")\n",
    "    format_1 = predict_string.rstrip(\"\\n\")\n",
    "    format_2 = format_1.replace(' ','')\n",
    "    format_3 = format_2.replace('+0.j','')\n",
    "    format_4  = format_3.replace('{\"prediction\":\"[',\"\")\n",
    "    format_5  = format_4.replace(']\"}','')\n",
    "    #print(\"Printing format 5\", format_5)\n",
    "    format_6 = str(format_5)\n",
    "    format_6 = format_6.replace(\"\\\\n\",\"\")\n",
    "    #fin = np.fromstring(format_6, sep = \",\")\n",
    "    #print(\"final\", format_6)\n",
    "    \n",
    "    return format_6\n",
    "    \n",
    "def format_response_filter2(predict_string):\n",
    "    print(\"Entering Format_response\")\n",
    "    format_1 = predict_string.replace(\"\\n\",\"\")\n",
    "    format_2 = format_1.replace(' ','')\n",
    "    format_3 = format_2.replace('+0.j','')\n",
    "    format_4  = format_3.replace('{\"prediction\":\"[',\"\")\n",
    "    format_5  = format_4.replace(']\"}','')\n",
    "    format_5 = format_5.replace('\\n','')\n",
    "    print(\"Printing format 5\", format_5)\n",
    "    format_6 = str(format_5)\n",
    "    format_6 = predict_string.rstrip(\"\\n\")\n",
    "    fin = np.fromstring(format_6, sep = \",\")\n",
    "    print(\"final\", fin)\n",
    "    \n",
    "    return fin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unlike-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_dict(preds):\n",
    "    ltpdict=kite.ltp(token_list) #fetching end of minute price\n",
    "    latest = [] #iniatiing list\n",
    "    for token in token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price'])\n",
    "        \n",
    "    lat = np.asarray(latest)\n",
    "    indicator_list = preds > lat\n",
    "    print(indicator_list)\n",
    "    signal_dict = {}\n",
    "    for sym,ind in zip(symbolist,indicator_list):\n",
    "        signal_dict.update({sym:ind})\n",
    "    \n",
    "    trade_list = []\n",
    "    for key in signal_dict.keys():\n",
    "        if signal_dict[key] == True:\n",
    "            trade_list.append(key)\n",
    "    \n",
    "    print(trade_list)\n",
    "    trade_string = \"\"\n",
    "    for sym in trade_list:\n",
    "        trade_string += sym.lower() + \" \"\n",
    "        \n",
    "\n",
    "    \n",
    "    return trade_string\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subtle-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Fetch the Symbols to Trade in and Direction  ################################################\n",
    "### For Now Long Only\n",
    "signal_dict = {}\n",
    "def tradelist(symbols, token_list):\n",
    "    ####### generate string of symbols to feed to endpoint\n",
    "    \n",
    "    sym_string = \"\"\n",
    "    for sym in symbols:\n",
    "        sym_string += sym.lower() + \"%20\"\n",
    "    sym_string += \"?rank=1\" ## specific rank here of dmd here, -1 = full rank\n",
    "    url_string_optdmd = \"http://localhost:5000/fit_dmd/\" + sym_string\n",
    "  \n",
    "    \n",
    "    ####### Stream to Endpoint to Fit Model###########\n",
    "    r = requests.post(url_string_optdmd)\n",
    "    print(\"Need the array dim to confirm it is working\",r.text)\n",
    "    \n",
    "    ######## Fetch Latest State of System #############\n",
    "    ltpdict=kite.ltp(token_list) #fetching end of minute price\n",
    "    latest = [] #iniatiing list\n",
    "    for token in token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price']) \n",
    "        \n",
    "    ############# Pull for predictions #################\n",
    "    latest_string = \"\"\n",
    "    for late in latest:\n",
    "        latest_string += str(late) + \"%20\"\n",
    "    size = len(latest_string)\n",
    "    latest_string  = latest_string[:size - 3]\n",
    "    url_string_predict = \"http://localhost:5000/predict_dmd/\" + latest_string\n",
    "    print(url_string_predict)\n",
    "    p = requests.post(url_string_predict)\n",
    "    print(p.text)\n",
    "    resp = list(p.text.split(\",\"))\n",
    "    for i in range(len(resp)):\n",
    "        resp[i] = format_response_filter1(resp[i])\n",
    "        resp[i] = float(resp[i])\n",
    "    final = np.asarray(resp)\n",
    "    #final = format_response_filter1(p.text)\n",
    "    #final = format_response_filter2(final_1)\n",
    "    \n",
    "    ############ Convert to predictions to a signal dictionary ###########\n",
    "    trade_string = sig_dict(final) \n",
    "    #print(\"Need the array dim to confirm it is working\",p.text)\n",
    "    print(\"Trade String\", trade_string)    \n",
    "    return(trade_string) ###### return symbols to trade in string format \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "inner-windsor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:5000\n",
      "DEBUG:urllib3.connectionpool:http://localhost:5000 \"POST /fit_dmd/adaniports%20asianpaint%20axisbank%20bajaj-auto%20bajajfinsv%20bajfinance%20bhartiartl%20bpcl%20britannia%20cipla%20coalindia%20divislab%20drreddy%20eichermot%20grasim%20hcltech%20hdfc%20hdfcbank%20hdfclife%20heromotoco%20hindalco%20hindunilvr%20icicibank%20indusindbk%20infy%20ioc%20itc%20jswsteel%20kotakbank%20lt%20m&m%20maruti%20nestleind%20ntpc%20ongc%20powergrid%20reliance%20sbilife%20sbin%20shreecem%20sunpharma%20tataconsum%20tatamotors%20tatasteel%20tcs%20techm%20titan%20ultracemco%20upl%20wipro%20?rank=1 HTTP/1.1\" 200 9\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=3861249&i=60417&i=1510401&i=4267265&i=4268801&i=81153&i=2714625&i=134657&i=140033&i=177665&i=5215745&i=2800641&i=225537&i=232961&i=315393&i=1850625&i=340481&i=341249&i=119553&i=345089&i=348929&i=356865&i=1270529&i=1346049&i=408065&i=415745&i=424961&i=3001089&i=492033&i=2939649&i=519937&i=2815745&i=4598529&i=2977281&i=633601&i=3834113&i=738561&i=5582849&i=779521&i=794369&i=857857&i=878593&i=884737&i=895745&i=2953217&i=3465729&i=897537&i=2952193&i=2889473&i=969473 HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): localhost:5000\n",
      "DEBUG:urllib3.connectionpool:http://localhost:5000 \"POST /predict_dmd/706%202998.7%20759.55%203836.95%2014313.55%206161.7%20635.85%20453.55%203617.9%20903.65%20144.35%204944%204696.05%202569.95%201494.85%201116.75%202696.35%201519.7%20674%202781.85%20441.6%202402.15%20704.35%201027.2%201708.6%20104.55%20211.7%20743.3%201780.9%201662.9%20779.8%207003.2%2018275.9%20118.6%20116%20186.2%202128.9%201139.55%20427.25%2027010%20782%20802.4%20306.65%201417.9%203429.5%201385.95%201834.7%207501.2%20777.35%20609.75 HTTP/1.1\" 200 804\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=3861249&i=60417&i=1510401&i=4267265&i=4268801&i=81153&i=2714625&i=134657&i=140033&i=177665&i=5215745&i=2800641&i=225537&i=232961&i=315393&i=1850625&i=340481&i=341249&i=119553&i=345089&i=348929&i=356865&i=1270529&i=1346049&i=408065&i=415745&i=424961&i=3001089&i=492033&i=2939649&i=519937&i=2815745&i=4598529&i=2977281&i=633601&i=3834113&i=738561&i=5582849&i=779521&i=794369&i=857857&i=878593&i=884737&i=895745&i=2953217&i=3465729&i=897537&i=2952193&i=2889473&i=969473 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need the array dim to confirm it is working [50,2621]\n",
      "http://localhost:5000/predict_dmd/706%202998.7%20759.55%203836.95%2014313.55%206161.7%20635.85%20453.55%203617.9%20903.65%20144.35%204944%204696.05%202569.95%201494.85%201116.75%202696.35%201519.7%20674%202781.85%20441.6%202402.15%20704.35%201027.2%201708.6%20104.55%20211.7%20743.3%201780.9%201662.9%20779.8%207003.2%2018275.9%20118.6%20116%20186.2%202128.9%201139.55%20427.25%2027010%20782%20802.4%20306.65%201417.9%203429.5%201385.95%201834.7%207501.2%20777.35%20609.75\n",
      "{\"prediction\":\"[  607.72605815, 2326.39798742,  908.99083217, 4703.2265014 ,\\n  8930.02763879, 3930.17183233,  687.0113467 ,  601.501017  ,\\n  3860.35799402,  998.52535091,  417.64800085, 2827.02655218,\\n  5342.64342429, 3384.02112297, 1478.7487487 ,  885.72028127,\\n  2867.31784799, 1518.77761591, 1106.72095012, 4768.08144135,\\n   329.6759819 , 2455.38541245,  591.54902864, 1830.0776953 ,\\n  1194.60091992,  204.71252425,  390.67972346,  423.40520981,\\n  1867.46914187, 1903.29973015, 1078.66670766, 9841.25193838,\\n 17493.6450065 ,  199.31888374,  256.73977312,  293.51382258,\\n  1831.78318373, 1844.7918284 ,  457.98797501,28202.39087932,\\n   967.11834367,  483.22360104,  503.28319539,  866.32098433,\\n  2990.70105422, 1052.5529759 , 1389.36172027, 6561.67876182,\\n   746.10720183,  428.28453353]\"}\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "Entering Format_response\n",
      "[False False  True  True False False  True  True  True  True  True False\n",
      "  True  True False False  True False  True  True False  True False  True\n",
      " False  True  True False  True  True  True  True False  True  True  True\n",
      " False  True  True  True  True False  True False False False False False\n",
      " False False]\n",
      "['AXISBANK', 'BAJAJ-AUTO', 'BHARTIARTL', 'BPCL', 'BRITANNIA', 'CIPLA', 'COALINDIA', 'DRREDDY', 'EICHERMOT', 'HDFC', 'HDFCLIFE', 'HEROMOTOCO', 'HINDUNILVR', 'INDUSINDBK', 'IOC', 'ITC', 'KOTAKBANK', 'LT', 'M&M', 'MARUTI', 'NTPC', 'ONGC', 'POWERGRID', 'SBILIFE', 'SBIN', 'SHREECEM', 'SUNPHARMA', 'TATAMOTORS']\n",
      "Trade String axisbank bajaj-auto bhartiartl bpcl britannia cipla coalindia drreddy eichermot hdfc hdfclife heromotoco hindunilvr indusindbk ioc itc kotakbank lt m&m maruti ntpc ongc powergrid sbilife sbin shreecem sunpharma tatamotors \n"
     ]
    }
   ],
   "source": [
    "pred = tradelist(symbolist, token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "geographic-ethics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pypfopt.expected_returns import mean_historical_return\\nfrom pypfopt.risk_models import CovarianceShrinkage\\nmu = mean_historical_return(df)\\nS = CovarianceShrinkage(df).ledoit_wolf()\\n\\nfrom pypfopt.efficient_frontier import EfficientFrontier\\nef = EfficientFrontier(mu, S)\\nweights = ef.max_sharpe()\\nweights\\n    \\n    \\n###### Heirarchal Risk Parity\\nfrom pypfopt import HRPOpt\\n\\nreturns = df.pct_change()\\nhrp = HRPOpt(returns)\\nweights = hrp.optimize()\\nhrp.portfolio_performance(verbose=True)\\nprint(weights)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################Portfolio Opimization###########\n",
    "\"\"\"\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "mu = mean_historical_return(df)\n",
    "S = CovarianceShrinkage(df).ledoit_wolf()\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "ef = EfficientFrontier(mu, S)\n",
    "weights = ef.max_sharpe()\n",
    "weights\n",
    "    \n",
    "    \n",
    "###### Heirarchal Risk Parity\n",
    "from pypfopt import HRPOpt\n",
    "\n",
    "returns = df.pct_change()\n",
    "hrp = HRPOpt(returns)\n",
    "weights = hrp.optimize()\n",
    "hrp.portfolio_performance(verbose=True)\n",
    "print(weights)\n",
    "\"\"\"    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "editorial-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Heirarchal Risk Parity ########\n",
    "from pypfopt import HRPOpt\n",
    "def get_opt_portfolio_hrp(trade_string):\n",
    "    df = fit(trade_string, rank = 1)\n",
    "    ret = df.pct_change()\n",
    "    hrp = HRPOpt(ret)\n",
    "    weights = hrp.optimize()\n",
    "    hrp.portfolio_performance(verbose=True)\n",
    "    #plotting.plot_dendrogram(hrp)\n",
    "    \n",
    "    return(weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quantitative-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:mysql.connector.connection:new_auth_plugin: mysql_native_password\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['axisbank', 'hdfc', 'hdfcbank', 'indusindbk']\n",
      "axisbank\n",
      "   index       date    open    high     low   close    volume\n",
      "0      0 2011-01-03  273.00  274.40  268.46  273.53   5266099\n",
      "1      1 2011-01-04  274.58  275.32  268.70  269.59   6919074\n",
      "2      2 2011-01-05  270.20  270.20  260.60  262.18   8749389\n",
      "3      3 2011-01-06  263.27  264.42  260.00  261.17   3967169\n",
      "4      4 2011-01-07  260.07  260.07  252.78  256.13  12047914\n",
      "hdfc\n",
      "   index       date   open   high     low   close   volume\n",
      "0      0 2011-01-03  737.9  737.9  724.00  728.20   768310\n",
      "1      1 2011-01-04  731.0  738.8  725.30  731.75  2071437\n",
      "2      2 2011-01-05  727.8  727.8  706.15  708.10  1346235\n",
      "3      3 2011-01-06  713.7  714.7  700.80  706.90  1579745\n",
      "4      4 2011-01-07  703.1  708.7  680.00  683.90  2377426\n",
      "hdfcbank\n",
      "   index       date    open    high     low   close   volume\n",
      "0      0 2011-01-03  237.00  239.95  235.05  239.05  2699194\n",
      "1      1 2011-01-04  238.65  238.80  233.30  234.55  4142064\n",
      "2      2 2011-01-05  234.95  234.95  229.75  230.80  3912959\n",
      "3      3 2011-01-06  231.60  234.25  230.90  232.75  2717544\n",
      "4      4 2011-01-07  232.60  232.60  226.10  226.95  3974004\n",
      "indusindbk\n",
      "   index       date    open    high     low   close   volume\n",
      "0      0 2011-01-03  265.90  269.85  264.00  264.65   386120\n",
      "1      1 2011-01-04  265.00  266.45  254.55  255.75   607282\n",
      "2      2 2011-01-05  255.75  255.75  245.00  249.05   810698\n",
      "3      3 2011-01-06  248.00  252.80  243.10  243.90   493824\n",
      "4      4 2011-01-07  250.00  250.50  226.00  230.25  1942697\n",
      "Expected annual return: 18.9%\n",
      "Annual volatility: 24.4%\n",
      "Sharpe Ratio: 0.69\n"
     ]
    }
   ],
   "source": [
    "weight_dict = get_opt_portfolio_hrp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "joined-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mean Variance Optimized ######\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "def get_opt_portfolio_mean_var(df):\n",
    "    mu = mean_historical_return(df)\n",
    "    S = CovarianceShrinkage(df).ledoit_wolf()\n",
    "    \n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    weights = ef.max_sharpe()\n",
    "    return(weights)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "clear-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=1510401&i=340481&i=341249&i=1346049 HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "##### Form Lists to Pass to Write Order #####\n",
    "\n",
    "trade_symbolist = []\n",
    "for sym in weight_dict.keys():\n",
    "    trade_symbolist.append(sym)\n",
    "\n",
    "weight_list = []\n",
    "for sym in weight_dict.keys():\n",
    "    weight_list.append(weight_dict[sym])\n",
    "\n",
    "poslist = []\n",
    "for wei in weight_list:\n",
    "    poslist.append(0)\n",
    "\n",
    "trade_token_list = [] \n",
    "for sym in trade_symbolist:\n",
    "    trade_token_list.append(instrumentLookup(sym.upper()))    \n",
    "\n",
    "ltpdict=kite.ltp(trade_token_list) #fetching end of minute price\n",
    "latest = [] #iniatiing list\n",
    "\n",
    "for token in trade_token_list:  \n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "order_index = 1\n",
    "        \n",
    "\n",
    "len(weight_list)\n",
    "equal_weight_list = []\n",
    "for i in range(len(weight_list)):\n",
    "    equal_weight_list.append(1/len(weight_list))\n",
    "\n",
    "final_weight_list = []\n",
    "for i,j in zip(weight_list,equal_weight_list):\n",
    "    final_weight_list.append((i*0.5+j*1.5)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "neural-production",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): masterswift.mastertrust.co.in:443\n",
      "DEBUG:urllib3.connectionpool:https://masterswift.mastertrust.co.in:443 \"GET /api/v2/contracts.json?exchanges=NSE HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# download the data\n",
    "j = requests.get(url=\"https://masterswift.mastertrust.co.in/api/v2/contracts.json?exchanges=NSE\")\n",
    "\n",
    "# looks to be json so let's see if json will load it\n",
    "content = json.loads(j.content)\n",
    "df = pd.DataFrame.from_dict(content['NSE'])\n",
    "\n",
    "mt_token_map = {}\n",
    "for sym,tok in zip(mt_df.trading_symbol, mt_df.code):\n",
    "    mt_token_map.update({sym:tok})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unknown-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load capital avaiblabl \n",
    "id_list = ['NL0119440']\n",
    "#capital_dict = {}\n",
    "#for i in id_list:\n",
    "    #df_temp = pd.read_sql('SELECT * FROM Investor_14FD050 WHERE Date = \"2021-07-16\"', engine_cloud_investor_log)\n",
    "    #capitak.update({sym:tok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "collaborative-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = final_weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "olive-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 12:15:52\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "# getting utc timezone\n",
    "utc = pytz.utc\n",
    "# getting timezone by name\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "# getting datetime of specified timezone\n",
    "now = datetime.now(tz=ist)\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caring-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(final_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adjacent-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "position_dict = {}\n",
    "def write_orderr(symbol,perc,price,pos):    \n",
    "    \n",
    "    capital = 50000\n",
    "    posnew=int(capital*perc/price) \n",
    "    #print(posnew)\n",
    "    global order_index\n",
    "    global current_time\n",
    "    now = datetime.now(tz=ist)\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    position_dict.update({symbol:posnew})\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        ################\n",
    "\n",
    "        quantity=posnew-pos\n",
    "        qty=int(quantity)\n",
    "        \n",
    "        if posnew*pos>=0:\n",
    "            if qty==0:\n",
    "                pass\n",
    "            elif qty>0:\n",
    "                \n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "                \n",
    "            else:\n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "\n",
    "        elif posnew*pos<0:\n",
    "            if pos>0:\n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "                \n",
    "            else: \n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "psychological-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def request_generator(token,order_side,price,quantity,client_id,auth):\n",
    "    \n",
    "    \n",
    "    url = \"https://masterswift-beta.mastertrust.co.in/api/v1/orders?exchange=NSE&instrument_token=\" +str(token)+\"&order_side=\" +str(order_side) + \"&order_type=LIMIT&price=\"+str(price)+\"&product=NRML&quantity=\"+str(quantity)+\"&validity=DAY&user_order_id=15&client_id=\" +str(client_id)\n",
    "    \n",
    "    #url = \"https://masterswift-beta.mastertrust.co.in/api/v1/orders?exchange=NSE&instrument_token=\" \\\n",
    "    #+ str(token) \"&order_side=\" # +str(order_side) + \"&order_type=LIMIT&price=\" # + str(price) + \"&product=NRML&quantity=\" + \"&validity=DAY&user_order_id=\\\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'x-device-type': 'WEB',\n",
    "      'client_id': client_id,\n",
    "      'x-authorization-token': auth\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "electronic-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-13\n"
     ]
    }
   ],
   "source": [
    "############## Get date for today ###########################\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "million-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Fetch auth tokens for client orders ############\n",
    "auth_token_dict = {}\n",
    "id_list =  ['NL0119440']\n",
    "df = pd.read_csv('/home/ec2-user/trading/Data/Equity Pipeline/Tokens/auth_tokens_' + str(today) + '.csv')\n",
    "for i,tk in zip(id_list,df.Token):\n",
    "    auth_token_dict.update({i:tk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "animated-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiplier(idx):\n",
    "    account_dict = {'NL0119440' : 1 ,'NL0120070' : 1,'NL0120099' : 1 ,'NL01225' : 1}\n",
    "    #print(account_dict[idx])\n",
    "    return account_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "extraordinary-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "position_dict = {}\n",
    "\n",
    "def write_order_multi(token,perc,price,pos):    \n",
    "    \n",
    "    capital = 50000\n",
    "    global order_index\n",
    "    posnew=int(capital*perc/price) \n",
    "    position_dict.update({symbol.upper() + '-EQ':posnew})\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        ################\n",
    "\n",
    "        quantity=posnew-pos\n",
    "        qty=int(quantity)\n",
    "        \n",
    "        random.shuffle(id_list)\n",
    "\n",
    "        for idx in id_list:\n",
    "            multiplier = get_multiplier(idx)\n",
    "        \n",
    "        \n",
    "            if posnew*pos>=0:\n",
    "                if qty==0:\n",
    "                    pass\n",
    "                elif qty>0:\n",
    "                    \n",
    "                    print(token,'BUY',price,qty*get_multiplier(idx),idx,symbol)\n",
    "                    \n",
    "                    #request_generator(token,'BUY',price,qty*get_multiplier(idx),idx,auth_token_dict[idx])\n",
    "\n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else:\n",
    "                    request_generator(token,'SELL',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "                      \n",
    "\n",
    "            elif posnew*pos<0:\n",
    "                if pos>0:\n",
    "                    \n",
    "                    request_generator(token,'SELL',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else: \n",
    "                    \n",
    "                    \n",
    "                    request_generator(token,'BUY',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "chronic-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Live Server\n",
    "def store_order():\n",
    "      \n",
    "    \n",
    "    file = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "    fil = open(file,\"r\")\n",
    "    orders = fil.read()\n",
    "    fil.close()\n",
    "    \n",
    "    wrt = open('/home/ec2-user/trading/Trade/Positions/total_orders' + str(today) + '.csv', 'a') \n",
    "    wrt.write(orders)\n",
    "    wrt.close()\n",
    "                \n",
    "    #file = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv','w+')\n",
    "    #file.close()\n",
    "    print(\"streamed :D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "shaped-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Re-stream cancelled order ######\n",
    "import csv\n",
    "#order_regenerator(order_index,'POWERGRID-EQ',\"14FD050\",86,219.70)\n",
    "def order_regenerator(idx, indentifier, client_id, quantity,price):\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([idx,indentifier,quantity,client_id,\"LIMIT\",price,current_time])\n",
    "        \n",
    "    #stream_order()\n",
    "    \n",
    "    #filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "    #file = open(filepath,\"r\")\n",
    "    #orders = file.read()\n",
    "    #wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders.csv', 'a') \n",
    "    #wrt.write(orders)\n",
    "    #wrt.close\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mounted-target",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=1510401&i=340481&i=341249&i=1346049 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900 BUY 759.65 15 NL0119440 axisbank\n",
      "1330 BUY 2695.4 4 NL0119440 hdfc\n",
      "1333 BUY 1520.25 9 NL0119440 hdfcbank\n",
      "5258 BUY 1027.9 10 NL0119440 indusindbk\n",
      "streamed :D\n"
     ]
    }
   ],
   "source": [
    "#### Fetch Latest State and Write and Stream Order ######\n",
    "ltpdict=kite.ltp(trade_token_list) #fetching end of minute price\n",
    "latest = [] #iniatiing list\n",
    "\n",
    "for token in trade_token_list:  \n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "for symbol,perc,price,pos in zip(trade_symbolist,weight_list,latest,poslist):\n",
    "    write_order_multi(mt_token_map[symbol.upper() + \"-EQ\"],perc,price,pos)\n",
    "\n",
    "store_order()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "upset-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = order_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "demanding-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Parse tradefile from broker to CSV #######################################\n",
    "\n",
    "def get_trade_book(client_id, auth_token):\n",
    "    \n",
    "\n",
    "    url = \"https://masterswift-beta.mastertrust.co.in/api/v1/trades?client_id=\" + str(client_id)\n",
    "\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'x-device-type': 'WEB',\n",
    "      'x-authorization-token': auth_token,\n",
    "      'client_id': 'REST6'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    return json.loads(response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "incorporate-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): masterswift-beta.mastertrust.co.in:443\n",
      "DEBUG:urllib3.connectionpool:https://masterswift-beta.mastertrust.co.in:443 \"GET /api/v1/trades?client_id=NL0119440 HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "parameter_list = ['trade_number','trading_symbol','trade_price','trade_quantity', 'client_id', 'trade_time']\n",
    "outer_list = []\n",
    "\n",
    "for idx in id_list:\n",
    "    trade_dict = get_trade_book(idx,auth_token_dict[idx])  \n",
    "\n",
    "    for i in range(len(trade_dict['data']['trades'])):\n",
    "        inner_list = []\n",
    "        for para in parameter_list:\n",
    "            if para == 'trade_quantity':\n",
    "                if trade_dict['data']['trades'][i]['order_side'] == 'BUY':\n",
    "                    qt = trade_dict['data']['trades'][i][para]\n",
    "                    inner_list.append(qt)\n",
    "                else:\n",
    "                    qt = trade_dict['data']['trades'][i][para]\n",
    "                    inner_list.append(-qt)\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                inner_list.append(trade_dict['data']['trades'][i][para])\n",
    "        \n",
    "        outer_list.append(inner_list)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "trade_dataframe = pd.DataFrame(outer_list, columns = ['trade_number','symbol','trade_price','qty', 'client', 'trade_time'])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "worth-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=1510401&i=340481&i=341249&i=1346049 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL0119440\n",
      "Client dict {'AXISBANK-EQ': 0, 'HDFC-EQ': 0, 'HDFCBANK-EQ': 0, 'INDUSINDBK-EQ': 0}\n",
      "1\n",
      "Left position dict : {'AXISBANK-EQ': 15, 'HDFC-EQ': 4, 'HDFCBANK-EQ': 9, 'INDUSINDBK-EQ': 10}\n",
      "5900 AXISBANK-EQ 759.75\n",
      "5900 BUY 759.75 15 NL0119440 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJibGFja2xpc3Rfa2V5IjoiTkwwMTE5NDQwOjRKMmR4UDYvQnJEa0hJTmhycmZPZVEiLCJjbGllbnRfaWQiOiJOTDAxMTk0NDAiLCJjbGllbnRfdG9rZW4iOiJHRlpudEZRY3FJdnVQZTB5ajcxZWFBIiwiZGV2aWNlIjoiIiwiZXhwIjoxNjI4OTE3NTYwMzUwfQ.3CTpUJGkauzGAPBkrUUILe7aWVIyVZAH4SJV_VaHliE\n",
      "1330 HDFC-EQ 2702\n",
      "1330 BUY 2702 4 NL0119440 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJibGFja2xpc3Rfa2V5IjoiTkwwMTE5NDQwOjRKMmR4UDYvQnJEa0hJTmhycmZPZVEiLCJjbGllbnRfaWQiOiJOTDAxMTk0NDAiLCJjbGllbnRfdG9rZW4iOiJHRlpudEZRY3FJdnVQZTB5ajcxZWFBIiwiZGV2aWNlIjoiIiwiZXhwIjoxNjI4OTE3NTYwMzUwfQ.3CTpUJGkauzGAPBkrUUILe7aWVIyVZAH4SJV_VaHliE\n",
      "1333 HDFCBANK-EQ 1525\n",
      "1333 BUY 1525 9 NL0119440 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJibGFja2xpc3Rfa2V5IjoiTkwwMTE5NDQwOjRKMmR4UDYvQnJEa0hJTmhycmZPZVEiLCJjbGllbnRfaWQiOiJOTDAxMTk0NDAiLCJjbGllbnRfdG9rZW4iOiJHRlpudEZRY3FJdnVQZTB5ajcxZWFBIiwiZGV2aWNlIjoiIiwiZXhwIjoxNjI4OTE3NTYwMzUwfQ.3CTpUJGkauzGAPBkrUUILe7aWVIyVZAH4SJV_VaHliE\n",
      "5258 INDUSINDBK-EQ 1028.65\n",
      "5258 BUY 1028.65 10 NL0119440 eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJibGFja2xpc3Rfa2V5IjoiTkwwMTE5NDQwOjRKMmR4UDYvQnJEa0hJTmhycmZPZVEiLCJjbGllbnRfaWQiOiJOTDAxMTk0NDAiLCJjbGllbnRfdG9rZW4iOiJHRlpudEZRY3FJdnVQZTB5ajcxZWFBIiwiZGV2aWNlIjoiIiwiZXhwIjoxNjI4OTE3NTYwMzUwfQ.3CTpUJGkauzGAPBkrUUILe7aWVIyVZAH4SJV_VaHliE\n",
      "streamed :D\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "import ftplib\n",
    "\n",
    "#order_index = 1\n",
    "df = trade_dataframe\n",
    "random.shuffle(id_list)\n",
    "for clientid in id_list:\n",
    "    print(clientid)\n",
    "    client1_df = df[df.client == clientid]\n",
    "    client1_dict = {}\n",
    "\n",
    "    sub_list = list(client1_df.symbol.values)\n",
    "    for sym,qty in zip(client1_df.symbol,client1_df.qty):\n",
    "        \n",
    "        if sub_list.count(sym) == 1:\n",
    "            client1_dict.update({sym:qty})\n",
    "        else:\n",
    "            updated_qty = np.sum(client1_df[client1_df.symbol == sym].qty.values)\n",
    "            client1_dict.update({sym:updated_qty})\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Client dict\", client1_dict)\n",
    "    left_position_dict = {}\n",
    "    \n",
    "    print(get_multiplier(clientid))\n",
    "    for key in position_dict.keys():\n",
    "        try:\n",
    "            client1_dict[key.upper()]\n",
    "            \n",
    "            if client1_dict[key.upper()] != position_dict[key]*get_multiplier(clientid):\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)-client1_dict[key.upper()]})\n",
    "                \n",
    "               \n",
    "            \n",
    "        except:\n",
    "            if position_dict[key] > 0:\n",
    "                print(\"Not existing\", key,position_dict[key])\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)})#-client1_dict[key.upper()]})\n",
    "                \n",
    "            \n",
    "    print(\"Left position dict :\", left_position_dict)       \n",
    "    left_token_list = []            \n",
    "    for key in left_position_dict.keys():\n",
    "        left_token_list.append(mt_token_map[key.upper()])\n",
    "    \n",
    "    ltp_token_list = []\n",
    "    for key in left_position_dict.keys():\n",
    "        ltp_token_list.append(token_map[key.upper()])\n",
    "    \n",
    "        \n",
    "    \n",
    "    latest = [] #iniatiing list\n",
    "    \n",
    "    ltpdict=kite.ltp(ltp_token_list)\n",
    "\n",
    "    for token in ltp_token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "\n",
    "    for token,sym,lat in zip(left_token_list,left_position_dict.keys(),latest):\n",
    "        print(token,sym,lat)\n",
    "        print(token,'BUY',lat,left_position_dict[sym],clientid,auth_token_dict[clientid])\n",
    "        #request_generator(token,'BUY',lat,left_position_dict[sym],clientid,auth_token_dict[clientid])\n",
    "\n",
    "        order_regenerator(idx, sym.upper() + \"-EQ\",clientid,left_position_dict[sym],lat)\n",
    "        \n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/reorder_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'w+') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders' + str(today) + '.csv', 'a') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'w+') \n",
    "wrt.close()\n",
    "store_order()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "coral-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Store Existing Positions ###########################################\n",
    "existing_position = []\n",
    "for key in position_dict.keys():\n",
    "    existing_position.append(position_dict[key])\n",
    "\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict'+ str(today) + '.pkl','wb')\n",
    "pickle.dump(position_dict, a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "direct-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_index = 1\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-07.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "miniature-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=1510401&i=4267265&i=2714625&i=134657&i=140033&i=177665&i=5215745&i=225537&i=232961&i=315393&i=340481&i=341249&i=119553&i=345089&i=1346049&i=415745&i=424961&i=492033&i=2939649&i=519937&i=2815745&i=4598529&i=2977281&i=633601&i=3834113&i=5582849&i=779521&i=857857&i=884737&i=3465729 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamed :D\n"
     ]
    }
   ],
   "source": [
    "################################ SQUARING OFF #########################\n",
    "order_index = 1\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-23.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "####### Clear Existing Positions ##########\n",
    "existing_position = []\n",
    "trade_symbolist = []\n",
    "for key in position_dict.keys():\n",
    "    existing_position.append(position_dict[key])\n",
    "    trade_symbolist.append(key.replace(\"-EQ\",\"\"))\n",
    "weight_list = np.zeros(len(existing_position))\n",
    "\n",
    "\n",
    "latest = [] #iniatiing list\n",
    "trade_token_list = [] \n",
    "\n",
    "for sym in trade_symbolist:\n",
    "    trade_token_list.append(instrumentLookup(sym.upper()))  \n",
    "#print(trade_token_list)\n",
    "ltpdict=kite.ltp(trade_token_list)    \n",
    "for token in trade_token_list:\n",
    "    #print(token)\n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "for symbol,perc,price,pos in zip(trade_symbolist,weight_list,latest,existing_position):\n",
    "    write_order_multi(symbol,perc,price,pos)\n",
    "####### Stream Order #######\n",
    "stream_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "viral-feature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'axisbank': -18,\n",
       " 'bajaj-auto': -3,\n",
       " 'bhartiartl': -28,\n",
       " 'bpcl': -30,\n",
       " 'britannia': -5,\n",
       " 'cipla': -19,\n",
       " 'coalindia': -101,\n",
       " 'drreddy': -3,\n",
       " 'eichermot': -5,\n",
       " 'grasim': -9,\n",
       " 'hdfc': -5,\n",
       " 'hdfcbank': -10,\n",
       " 'hdfclife': -36,\n",
       " 'heromotoco': -4,\n",
       " 'indusindbk': -13,\n",
       " 'ioc': -128,\n",
       " 'itc': -81,\n",
       " 'kotakbank': -8,\n",
       " 'lt': -9,\n",
       " 'm&m': -18,\n",
       " 'maruti': -1,\n",
       " 'nestleind': -1,\n",
       " 'ntpc': -138,\n",
       " 'ongc': -120,\n",
       " 'powergrid': -74,\n",
       " 'sbilife': -36,\n",
       " 'sbin': -32,\n",
       " 'sunpharma': -23,\n",
       " 'tatamotors': -40,\n",
       " 'techm': -19}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-23.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "for key in position_dict.keys():\n",
    "    position_dict.update({key:-position_dict[key]})\n",
    "\n",
    "position_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "miniature-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = order_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "backed-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=225537 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14FD050\n",
      "Client dict {'GRASIM': -18, 'BHARTIARTL': -56, 'ITC': -162, 'HDFCBANK': -20, 'ONGC': -240, 'BRITANNIA': -10, 'INDUSINDBK': -26, 'AXISBANK': -36, 'BPCL': -60, 'MARUTI': -2, 'KOTAKBANK': -16, 'M&M': -36, 'BAJAJ-AUTO': -6, 'NESTLEIND': -2, 'DRREDDY': -6, 'CIPLA': -38, 'IOC': -256, 'HEROMOTOCO': -8, 'SUNPHARMA': -46, 'EICHERMOT': -10, 'SBILIFE': -72, 'TATAMOTORS': -80, 'HDFCLIFE': -72, 'HDFC': -10, 'TECHM': -38, 'SBIN': -64, 'POWERGRID': -148, 'LT': -18, 'COALINDIA': -202, 'NTPC': -276}\n",
      "2\n",
      "{}\n",
      "14FD053\n",
      "Client dict {'GRASIM': -9, 'BHARTIARTL': -28, 'ITC': -81, 'HDFCBANK': -10, 'IOC': -128, 'HEROMOTOCO': -4, 'HDFC': -5, 'SBIN': -32, 'CIPLA': -19, 'BPCL': -30, 'INDUSINDBK': -13, 'EICHERMOT': -5, 'POWERGRID': -74, 'MARUTI': -1, 'LT': -9, 'TECHM': -19, 'TATAMOTORS': -40, 'AXISBANK': -18, 'M&M': -18, 'ONGC': -120, 'SBILIFE': -36, 'SUNPHARMA': -23, 'COALINDIA': -101, 'BRITANNIA': -5, 'KOTAKBANK': -8, 'HDFCLIFE': -36, 'NTPC': -138, 'DRREDDY': -3, 'BAJAJ-AUTO': -3, 'NESTLEIND': -1}\n",
      "1\n",
      "{}\n",
      "14FD051\n",
      "Client dict {'GRASIM': -18, 'BHARTIARTL': -56, 'ITC': -162, 'HDFCBANK': -20, 'ONGC': -240, 'BRITANNIA': -10, 'INDUSINDBK': -26, 'AXISBANK': -36, 'BPCL': -60, 'MARUTI': -2, 'KOTAKBANK': -16, 'M&M': -36, 'BAJAJ-AUTO': -6, 'NESTLEIND': -2, 'POWERGRID': -148, 'CIPLA': -38, 'DRREDDY': -6, 'IOC': -256, 'HEROMOTOCO': -8, 'EICHERMOT': -10, 'SUNPHARMA': -46, 'SBILIFE': -72, 'TATAMOTORS': -80, 'HDFCLIFE': -72, 'HDFC': -10, 'TECHM': -38, 'SBIN': -64, 'LT': -18, 'COALINDIA': -202, 'NTPC': -276}\n",
      "2\n",
      "{}\n",
      "14FD052\n",
      "Client dict {'BHARTIARTL': -56, 'GRASIM': -18, 'ITC': -162, 'HDFCBANK': -20, 'MARUTI': -2, 'IOC': -256, 'HDFCLIFE': -72, 'HDFC': -10, 'SBIN': -64, 'CIPLA': -38, 'BPCL': -60, 'INDUSINDBK': -26, 'EICHERMOT': -10, 'POWERGRID': -148, 'LT': -18, 'TECHM': -38, 'TATAMOTORS': -80, 'AXISBANK': -36, 'M&M': -36, 'ONGC': -240, 'BRITANNIA': -10, 'KOTAKBANK': -16, 'NTPC': -276, 'SBILIFE': -72, 'HEROMOTOCO': -8, 'BAJAJ-AUTO': -6, 'COALINDIA': -202, 'SUNPHARMA': -46, 'NESTLEIND': -2}\n",
      "2\n",
      "Not existing drreddy -3\n",
      "{'drreddy': -6}\n",
      "drreddy 5289\n",
      "streamed :D\n",
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "########## For Squaring Off Existing Position Of Earlier Time ###################\n",
    "import ftplib\n",
    "\n",
    "# create a new FTP() instance\n",
    "session = ftplib.FTP()\n",
    "\n",
    "# connect to our FTP site\n",
    "session.connect('14.142.196.162' )\n",
    "\n",
    "# log into the FTP site\n",
    "session.login('administrator', 'Hello@123!')\n",
    "\n",
    "####### FINAL #####\n",
    "\n",
    "filename = 'JagjitTradeFile2.csv'\n",
    "\n",
    "localfile = open('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv', 'wb')\n",
    "session.retrbinary('RETR ' + filename, localfile.write, 1024)\n",
    "\n",
    "session.quit()\n",
    "localfile.close()\n",
    "\n",
    "order_index = 1\n",
    "df = pd.read_csv('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv',names =  ['index','symbol','foo','qty','client','date','time-stamp'])\n",
    "random.shuffle(id_list)\n",
    "for clientid in id_list:\n",
    "    print(clientid)\n",
    "    client1_df = df[df.client == clientid]\n",
    "    client1_dict = {}\n",
    "\n",
    "    sub_list = list(client1_df.symbol.values)\n",
    "    for sym,qty in zip(client1_df.symbol,client1_df.qty):\n",
    "        \n",
    "        if sub_list.count(sym) == 1:\n",
    "            client1_dict.update({sym:qty})\n",
    "        else:\n",
    "            updated_qty = np.sum(client1_df[client1_df.symbol == sym].qty.values)\n",
    "            client1_dict.update({sym:updated_qty})\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Client dict\", client1_dict)\n",
    "    left_position_dict = {}\n",
    "    \n",
    "    print(get_multiplier(clientid))\n",
    "    for key in position_dict.keys():\n",
    "        try:\n",
    "            client1_dict[key.upper()]\n",
    "            \n",
    "            if client1_dict[key.upper()] != position_dict[key]*get_multiplier(clientid):\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)-client1_dict[key.upper()]})\n",
    "                \n",
    "               \n",
    "            \n",
    "        except:\n",
    "            if position_dict[key] < 0:\n",
    "                print(\"Not existing\", key,position_dict[key])\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)})#-client1_dict[key.upper()]})\n",
    "                \n",
    "            \n",
    "           \n",
    "    left_token_list = []            \n",
    "    for key in left_position_dict.keys():\n",
    "        left_token_list.append(token_map[key.upper()])\n",
    "        \n",
    "    print(left_position_dict)\n",
    "    latest = [] #iniatiing list\n",
    "    try:\n",
    "        ltpdict=kite.ltp(left_token_list)\n",
    "\n",
    "        for token in left_token_list:  \n",
    "            latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "\n",
    "        for sym,lat in zip(left_position_dict.keys(),latest):\n",
    "            order_regenerator(idx, sym.upper() + \"-EQ\",clientid,left_position_dict[sym],lat)\n",
    "            print(sym,lat)\n",
    "            idx = idx + 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/reorder_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'w+') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders' + str(today) + '.csv', 'a') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'w+') \n",
    "wrt.close()\n",
    "stream_order()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# FOR SQAURE OFF ON SAME DAY, FIRST DOWNLOAD THE TRADE FILE AND REMOVE THE BUY TRADES ####################\n",
    "\n",
    "import ftplib\n",
    "\n",
    "# create a new FTP() instance\n",
    "session = ftplib.FTP()\n",
    "\n",
    "# connect to our FTP site\n",
    "session.connect('ip address' )\n",
    "\n",
    "# log into the FTP site\n",
    "session.login('username', 'password')\n",
    "\n",
    "####### FINAL #####\n",
    "\n",
    "filename = 'filename'\n",
    "\n",
    "localfile = open('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv', 'wb')\n",
    "session.retrbinary('RETR ' + filename, localfile.write, 1024)\n",
    "\n",
    "session.quit()\n",
    "localfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "color-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=134657 HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.kite.trade:443\n",
      "DEBUG:urllib3.connectionpool:https://api.kite.trade:443 \"GET /quote/ltp?i=134657 HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14FD050\n",
      "Client dict {'INDUSINDBK': -2, 'HDFCBANK': -1, 'EICHERMOT': -1, 'ONGC': -23, 'TECHM': -3, 'KOTAKBANK': -1, 'SBIN': -6, 'CIPLA': -3, 'NTPC': -27, 'LT': -1, 'BHARTIARTL': -5, 'M&M': -3, 'POWERGRID': -14, 'SUNPHARMA': -4, 'SBILIFE': -7, 'HDFCLIFE': -7, 'COALINDIA': -20, 'IOC': -24, 'ITC': -16, 'TATAMOTORS': -7, 'HINDUNILVR': -1, 'AXISBANK': -3, 'HDFC': -1}\n",
      "1\n",
      "Not existing bpcl -5\n",
      "{'bpcl': -5}\n",
      "bpcl 490.2\n",
      "14FD051\n",
      "Client dict {'INDUSINDBK': -4, 'HDFCBANK': -2, 'EICHERMOT': -2, 'ONGC': -46, 'TECHM': -6, 'KOTAKBANK': -2, 'BHARTIARTL': -10, 'SBIN': -12, 'CIPLA': -6, 'NTPC': -54, 'LT': -2, 'M&M': -6, 'POWERGRID': -28, 'SUNPHARMA': -8, 'SBILIFE': -14, 'HDFCLIFE': -14, 'COALINDIA': -40, 'IOC': -48, 'ITC': -32, 'TATAMOTORS': -14, 'HINDUNILVR': -2, 'AXISBANK': -6, 'HDFC': -2}\n",
      "2\n",
      "Not existing bpcl -5\n",
      "{'bpcl': -10}\n",
      "bpcl 490.2\n",
      "streamed :D\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    }
   ],
   "source": [
    "order_index = 97\n",
    "idx = 97\n",
    "df = pd.read_csv('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv',names =  ['index','symbol','foo','qty','client','date','time-stamp'])\n",
    "random.shuffle(id_list)\n",
    "for clientid in id_list:\n",
    "    print(clientid)\n",
    "    client1_df = df[df.client == clientid]\n",
    "    client1_dict = {}\n",
    "\n",
    "    sub_list = list(client1_df.symbol.values)\n",
    "    for sym,qty in zip(client1_df.symbol,client1_df.qty):\n",
    "        \n",
    "        if sub_list.count(sym) == 1:\n",
    "            client1_dict.update({sym:qty})\n",
    "        else:\n",
    "            updated_qty = np.sum(client1_df[client1_df.symbol == sym].qty.values)\n",
    "            client1_dict.update({sym:updated_qty})\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Client dict\", client1_dict)\n",
    "    left_position_dict = {}\n",
    "    \n",
    "    print(get_multiplier(clientid))\n",
    "    for key in position_dict.keys():\n",
    "        try:\n",
    "            client1_dict[key.upper()]\n",
    "            \n",
    "            if client1_dict[key.upper()] != position_dict[key]*get_multiplier(clientid):\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)-client1_dict[key.upper()]})\n",
    "                \n",
    "               \n",
    "            \n",
    "        except:\n",
    "            if position_dict[key] < 0:\n",
    "                print(\"Not existing\", key,position_dict[key])\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)})#-client1_dict[key.upper()]})\n",
    "                \n",
    "            \n",
    "           \n",
    "    left_token_list = []            \n",
    "    for key in left_position_dict.keys():\n",
    "        left_token_list.append(token_map[key.upper()])\n",
    "        \n",
    "    print(left_position_dict)\n",
    "    latest = [] #iniatiing list\n",
    "    try:\n",
    "        ltpdict=kite.ltp(left_token_list)\n",
    "\n",
    "        for token in left_token_list:  \n",
    "            latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "\n",
    "        for sym,lat in zip(left_position_dict.keys(),latest):\n",
    "            order_regenerator(idx, sym.upper() + \"-EQ\",clientid,left_position_dict[sym],lat)\n",
    "            print(sym,lat)\n",
    "            idx = idx + 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/reorder_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'w+') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders' + str(today) + '.csv', 'a') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'w+') \n",
    "wrt.close()\n",
    "stream_order()\n",
    "%time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
