{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "from kiteconnect import KiteConnect\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ftplib\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Connect to Data Feed #######\n",
    "##################\n",
    "kite = KiteConnect(api_key = \"key\") \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "kite.login_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kite.generate_session(\"key\", api_secret=\"key\")\n",
    "kite.set_access_token(data[\"access_token\"])\n",
    "token = data[\"access_token\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_dump = kite.instruments(\"NSE\")\n",
    "def instrumentLookup(symbol):\n",
    "    instrument_df = pd.DataFrame(instrument_dump)\n",
    "    \"\"\"Looks up instrument token for a given script from instrument dump\"\"\"\n",
    "    try:\n",
    "        return instrument_df[instrument_df.tradingsymbol==symbol].instrument_token.values[0]\n",
    "    except:\n",
    "        return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-07-16.pkl','rb')\n",
    "position_dict = pickle.load(a_file)\n",
    "\n",
    "##### The Entry Portfolio Value #####\n",
    "trade_token_list = [] \n",
    "trade_symbolist = []\n",
    "for key in position_dict.keys():\n",
    "    trade_symbolist.append(key.upper())\n",
    "    trade_token_list.append(instrumentLookup(key.upper()))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Only if error in previous cell #############\n",
    "######################## if pickle dict not created then create dict from trade file ###########################\n",
    "df = pd.read_csv('/home/ec2-user/trading/Trade/Positions/total_orders2021-07-05.csv', names =  ['index','symbol','qty','client','type','date','time-stamp'])\n",
    "df1 = df[df.client == '14FD050']\n",
    "position_dict = {}\n",
    "for sym,qty in zip(df1.symbol, df1.qty):\n",
    "    position_dict.update({sym.lower().replace('-eq',''):qty})\n",
    "trade_token_list = [] \n",
    "trade_symbolist = []\n",
    "for key in position_dict.keys():\n",
    "    trade_symbolist.append(key.upper())\n",
    "    trade_token_list.append(instrumentLookup(key.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_file = open('/home/ec2-user/trading/Trade/Positions/position_dict'+ str(today) + '.pkl','wb')\n",
    "pickle.dump(position_dict, b_file)\n",
    "position_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = []#iniatiing list\n",
    "ltpdict=kite.ltp(trade_token_list)\n",
    "for token in trade_token_list:  \n",
    "    latest.append(ltpdict[str(token)]['last_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_portfolio = 0 \n",
    "current_equity_dict = {}\n",
    "for key,lat in zip(position_dict.keys(),latest):\n",
    "    current_portfolio += position_dict[key]*lat\n",
    "    current_equity_dict.update({key.upper() + \"-EQ\":lat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Live Server\n",
    "def stream_order():\n",
    "    \n",
    "\n",
    "\n",
    "    # create a new FTP() instance\n",
    "    session = ftplib.FTP()\n",
    "\n",
    "    # connect to our FTP site\n",
    "    session.connect('14.142.196.162' )\n",
    "\n",
    "    # log into the FTP site\n",
    "    session.login('administrator', 'Hello@123!')\n",
    "    \n",
    "    ####### FINAL #####\n",
    "    file = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv','rb') \n",
    "    session.storbinary('STOR orders_stream.csv', file)     # send the file\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "    file = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "    fil = open(file,\"r\")\n",
    "    orders = fil.read()\n",
    "    fil.close()\n",
    "    \n",
    "    wrt = open('/home/ec2-user/trading/Trade/Positions/total_orders' + str(today) + '.csv', 'a') \n",
    "    wrt.write(orders)\n",
    "    wrt.close()\n",
    "                \n",
    "    #file = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv','w+')\n",
    "    #file.close()\n",
    "    print(\"streamed :D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_mid_office():\n",
    "\n",
    "    # create a new FTP() instance\n",
    "    session = ftplib.FTP()\n",
    "\n",
    "    # connect to our FTP site\n",
    "    session.connect('3.108.109.191')\n",
    "\n",
    "    # log into the FTP site\n",
    "    session.login('analyst', 'Dplr23#!')\n",
    "\n",
    "\n",
    "    file = open('/home/ec2-user/trading/Trade/Positions/current.csv','rb') \n",
    "    session.storbinary('STOR /home/analyst/Current/current.csv', file)     # send the file\n",
    "    file.close()\n",
    "    \n",
    "    for client_id in id_list:\n",
    "        for file in file_type:\n",
    "            #print(path_format(client_id, file)[1])\n",
    "            localfile = open(path_format(client_id,file)[1], 'wb')\n",
    "            #print(path_format(client_id, file)[0])\n",
    "            session.retrbinary('RETR ' + path_format(client_id, file)[0], localfile.write, 1024)\n",
    "\n",
    "    session.quit()\n",
    "    localfile.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiplier(idx):\n",
    "    account_dict = {\"14FD050\":1, \"14FD051\" : 1, \"14FD052\": 1, \"14FD053\": 1, \"14FD055\": 1}\n",
    "    #print(account_dict[idx])\n",
    "    return account_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "position_dict = {}\n",
    "id_list = [\"14FD050\", \"14FD051\", \"14FD052\", \"14FD053\", \"14FD055\"]\n",
    "#id_list = [\"14FD050\"]\n",
    "\n",
    "\n",
    "\n",
    "def write_order_multi(symbol,perc,price,pos):    \n",
    "    \n",
    "    capital = 500000\n",
    "    posnew=int(capital*perc/price) \n",
    "    #print(posnew)\n",
    "    global order_index\n",
    "    global current_time\n",
    "    now = datetime.now(tz=ist)\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    position_dict.update({symbol:posnew})\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        ################\n",
    "\n",
    "        quantity=posnew-pos\n",
    "        qty=int(quantity)\n",
    "        \n",
    "        random.shuffle(id_list)\n",
    "\n",
    "        for idx in id_list:\n",
    "            multiplier = get_multiplier(idx)\n",
    "        \n",
    "        \n",
    "            if posnew*pos>=0:\n",
    "                if qty==0:\n",
    "                    pass\n",
    "                elif qty>0:\n",
    "\n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else:\n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "            elif posnew*pos<0:\n",
    "                if pos>0:\n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else: \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### on Monday enter Manually\n",
    "order_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## commands to make FTP requests #######################\n",
    "file_type = ['_NET_','_MTM_','_flaggedStocks_', '_exitFlag_',]\n",
    "id_list = ['14FD050', '14FD051', '14FD052', '14FD053','14FD055']\n",
    "def path_format(client_id, file_type):\n",
    "    read_path = '/home/analyst/mid_office/' + client_id + '/' + client_id + file_type + str(today) + '.csv'\n",
    "    write_path = '/home/ec2-user/trading/Trade/Positions/Equity/' + client_id + '/' + client_id + file_type + str(today) + '.csv'\n",
    "    \n",
    "    return read_path,write_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file =  open('/home/ec2-user/trading/Trade/Positions/position_dict' + str(today) + '.pkl','rb')\n",
    "position_dict = pickle.load(a_file)\n",
    "##### The Entry Portfolio Value #######\n",
    "entry_portfolio = 0 \n",
    "for key,lat in zip(position_dict.keys(),latest):\n",
    "    entry_portfolio += position_dict[key]*lat\n",
    "##### The Current Portfolio Value ######\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    print(\"Entering Loop\")\n",
    "    latest = [] #iniatiing list\n",
    "    ltpdict=kite.ltp(trade_token_list)\n",
    "    for token in trade_token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price']) \n",
    "    current_portfolio = 0 \n",
    "    for key,lat in zip(position_dict.keys(),latest):\n",
    "        current_portfolio += position_dict[key]*lat\n",
    "        \n",
    "    print(current_portfolio)\n",
    "    \n",
    "    if current_portfolio <= 0.97*entry_portfolio:\n",
    "       ####### Clear Existing Positions ##########\n",
    "        existing_position = []\n",
    "        trade_symbolist = []\n",
    "        for key in position_dict.keys():\n",
    "            existing_position.append(position_dict[key])\n",
    "            trade_symbolist.append(key.replace(\"-EQ\",\"\"))\n",
    "        weight_list = np.zeros(len(existing_position))\n",
    "\n",
    "        latest = [] #iniatiing list\n",
    "        trade_token_list = [] \n",
    "\n",
    "        for sym in trade_symbolist:\n",
    "            trade_token_list.append(instrumentLookup(sym.upper()))  \n",
    "        #print(trade_token_list)\n",
    "        ltpdict=kite.ltp(trade_token_list)    \n",
    "        for token in trade_token_list:\n",
    "            #print(token)\n",
    "            latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "        for symbol,perc,price,pos in zip(trade_symbolist,weight_list,latest,existing_position):\n",
    "            write_order_multi(symbol,perc,price,pos)\n",
    "        ####### Stream Order #######\n",
    "        stream_order()\n",
    "\n",
    "        break\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['Symbol', 'Price'])\n",
    "\n",
    "    symbolist = []\n",
    "    for i in position_dict.keys():\n",
    "        symbolist.append(i.upper())\n",
    "\n",
    "    for i,j in zip(range(len(symbolist)), range(len(latest))):\n",
    "        df.loc[i] = [symbolist[i],latest[j]]\n",
    "\n",
    "    df.to_csv('/home/ec2-user/trading/Trade/Positions/current.csv', header = False)\n",
    "    path = '/home/ec2-user/trading/Trade/Positions/current.csv'\n",
    "   \n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        last = len(lines) - 1\n",
    "        lines[last] = lines[last].replace('\\r','').replace('\\n','')\n",
    "    with open(path, 'w') as wr:\n",
    "        wr.writelines(lines)\n",
    "    #stream_mid_office()\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    time.sleep(1)\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_trade)",
   "language": "python",
   "name": "conda_trade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
