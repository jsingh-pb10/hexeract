{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/ec2-user/trading/Data/cloud_database_connector.ipynb\n",
    "import requests\n",
    "from kiteconnect import KiteConnect\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pypfopt import HRPOpt\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "import pytz\n",
    "import json\n",
    "from datetime import datetime\n",
    "# getting utc timezone\n",
    "utc = pytz.utc\n",
    "# getting timezone by name\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "# getting datetime of specified timezone\n",
    "now = datetime.now(tz=ist)\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-maldives",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Connect to Data Feed #######\n",
    "##################\n",
    "kite = KiteConnect(api_key = \"key\") \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "kite.login_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kite.generate_session(\"key\", api_secret=\"key\")\n",
    "kite.set_access_token(data[\"access_token\"])\n",
    "token = data[\"access_token\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Fetch Symbols and Respective Tokens From Zerodha ###############\n",
    "instrument_dump = kite.instruments(\"NSE\")\n",
    "def instrumentLookup(symbol):\n",
    "    instrument_df = pd.DataFrame(instrument_dump)\n",
    "    \"\"\"Looks up instrument token for a given script from instrument dump\"\"\"\n",
    "    try:\n",
    "        return instrument_df[instrument_df.tradingsymbol==symbol].instrument_token.values[0]\n",
    "    except:\n",
    "        return -1\n",
    "    \n",
    "j = requests.get(url=\"https://masterswift.mastertrust.co.in/api/v2/contracts.json?exchanges=NSE\")\n",
    "\n",
    "# looks to be json so let's see if json will load it\n",
    "content = json.loads(j.content)\n",
    "mt_df = pd.DataFrame.from_dict(content['NSE'])\n",
    "\n",
    "\n",
    "df = pd.read_csv('nifty50.csv')\n",
    "symbolist = []\n",
    "for sym in df.Symbol:\n",
    "    symbolist.append(sym)\n",
    "    \n",
    "symbolist = sorted(symbolist)\n",
    "token_list = [] \n",
    "for symbol in symbolist:\n",
    "    token_list.append(instrumentLookup(symbol))\n",
    "    \n",
    "token_map = {}\n",
    "for tok,sym in zip(token_list, symbolist):\n",
    "    token_map.update({sym.upper() + '-EQ':tok})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### Form A Symbolist and Tokenlist #################################################################\n",
    "import datetime\n",
    "dt = datetime.datetime.now()\n",
    "month = dt.strftime(\"%B\")\n",
    "def get_trading_symbols():\n",
    "    futureslist = []\n",
    "    for tick in tickdatalist:\n",
    "        if \"21APRFUT\" in tick:\n",
    "            futureslist.append(tick) ### get the front month symbols\n",
    "            \n",
    "    ###### Get the your securities universe #####\n",
    "    df = pd.read_csv('/home/ec2-user/trading/Trade/nifty50.csv')\n",
    "    cashlist  = []\n",
    "    for sym in df.Symbol:\n",
    "        cashlist.append(sym)\n",
    "    #print(cashlist)\n",
    "    equity_fut =  []\n",
    "    for cash in cashlist:\n",
    "        fut_sym = cash + \"21APRFUT\"\n",
    "        equity_fut.append(fut_sym)\n",
    "        \n",
    "    #print(equity_fut)\n",
    "    \n",
    "    currency_fut = ['USDINR21APRFUT', 'EURINR21APRFUT','GBPINR21APRFUT','JPYINR21APRFUT']\n",
    "    com_list= ['GOLD', 'CRUDE', \"NATURALGAS\",\"SILVER\"]\n",
    "    \n",
    "    \n",
    "    return cashlist #+ equity_fut\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def format_response_filter1(predict_string):\n",
    "    print(\"Entering Format_response\")\n",
    "    format_1 = predict_string.rstrip(\"\\n\")\n",
    "    format_2 = format_1.replace(' ','')\n",
    "    format_3 = format_2.replace('+0.j','')\n",
    "    format_4  = format_3.replace('{\"prediction\":\"[',\"\")\n",
    "    format_5  = format_4.replace(']\"}','')\n",
    "    format_6 = str(format_5)\n",
    "    format_6 = format_6.replace(\"\\\\n\",\"\")\n",
    "\n",
    "    \n",
    "    return format_6\n",
    "    \n",
    "def format_response_filter2(predict_string):\n",
    "    print(\"Entering Format_response\")\n",
    "    format_1 = predict_string.replace(\"\\n\",\"\")\n",
    "    format_2 = format_1.replace(' ','')\n",
    "    format_3 = format_2.replace('+0.j','')\n",
    "    format_4  = format_3.replace('{\"prediction\":\"[',\"\")\n",
    "    format_5  = format_4.replace(']\"}','')\n",
    "    format_5 = format_5.replace('\\n','')\n",
    "    print(\"Printing format 5\", format_5)\n",
    "    format_6 = str(format_5)\n",
    "    format_6 = predict_string.rstrip(\"\\n\")\n",
    "    fin = np.fromstring(format_6, sep = \",\")\n",
    "    print(\"final\", fin)\n",
    "    \n",
    "    return fin\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_dict(preds):\n",
    "    ltpdict=kite.ltp(token_list) #fetching end of minute price\n",
    "    latest = [] #iniatiing list\n",
    "    for token in token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price'])\n",
    "        \n",
    "    lat = np.asarray(latest)\n",
    "    indicator_list = preds > lat\n",
    "    print(indicator_list)\n",
    "    signal_dict = {}\n",
    "    for sym,ind in zip(symbolist,indicator_list):\n",
    "        signal_dict.update({sym:ind})\n",
    "    \n",
    "    trade_list = []\n",
    "    for key in signal_dict.keys():\n",
    "        if signal_dict[key] == True:\n",
    "            trade_list.append(key)\n",
    "    \n",
    "    print(trade_list)\n",
    "    trade_string = \"\"\n",
    "    for sym in trade_list:\n",
    "        trade_string += sym.lower() + \" \"\n",
    "        \n",
    "\n",
    "    \n",
    "    return trade_string\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Fetch the Symbols to Trade in and Direction  ################################################\n",
    "### For Now Long Only\n",
    "signal_dict = {}\n",
    "def tradelist(symbols, token_list):\n",
    "    ####### generate string of symbols to feed to endpoint\n",
    "    \n",
    "    sym_string = \"\"\n",
    "    for sym in symbols:\n",
    "        sym_string += sym.lower() + \"%20\"\n",
    "    sym_string += \"?rank=1\" ## specific rank here of dmd here, -1 = full rank\n",
    "    url_string_optdmd = \"http://localhost:5000/fit_dmd/\" + sym_string\n",
    "  \n",
    "    \n",
    "    ####### Stream to Endpoint to Fit Model###########\n",
    "    r = requests.post(url_string_optdmd)\n",
    "    print(\"Need the array dim to confirm it is working\",r.text)\n",
    "    \n",
    "    ######## Fetch Latest State of System #############\n",
    "    ltpdict=kite.ltp(token_list) #fetching end of minute price\n",
    "    latest = [] #iniatiing list\n",
    "    for token in token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price']) \n",
    "        \n",
    "    ############# Pull for predictions #################\n",
    "    latest_string = \"\"\n",
    "    for late in latest:\n",
    "        latest_string += str(late) + \"%20\"\n",
    "    size = len(latest_string)\n",
    "    latest_string  = latest_string[:size - 3]\n",
    "    url_string_predict = \"http://localhost:5000/predict_dmd/\" + latest_string\n",
    "    print(url_string_predict)\n",
    "    p = requests.post(url_string_predict)\n",
    "    print(p.text)\n",
    "    resp = list(p.text.split(\",\"))\n",
    "    for i in range(len(resp)):\n",
    "        resp[i] = format_response_filter1(resp[i])\n",
    "        resp[i] = float(resp[i])\n",
    "    final = np.asarray(resp)\n",
    "    #final = format_response_filter1(p.text)\n",
    "    #final = format_response_filter2(final_1)\n",
    "    \n",
    "    ############ Convert to predictions to a signal dictionary ###########\n",
    "    trade_string = sig_dict(final) \n",
    "    #print(\"Need the array dim to confirm it is working\",p.text)\n",
    "    print(\"Trade String\", trade_string)    \n",
    "    return(trade_string) ###### return symbols to trade in string format \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-windsor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = tradelist(symbolist, token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Heirarchal Risk Parity ########\n",
    "from pypfopt import HRPOpt\n",
    "def get_opt_portfolio_hrp(trade_string):\n",
    "    df = fit(trade_string, rank = 1)\n",
    "    ret = df.pct_change()\n",
    "    hrp = HRPOpt(ret)\n",
    "    weights = hrp.optimize()\n",
    "    hrp.portfolio_performance(verbose=True)\n",
    "    #plotting.plot_dendrogram(hrp)\n",
    "    \n",
    "    return(weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = get_opt_portfolio_hrp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mean Variance Optimized ######\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "def get_opt_portfolio_mean_var(df):\n",
    "    mu = mean_historical_return(df)\n",
    "    S = CovarianceShrinkage(df).ledoit_wolf()\n",
    "    \n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    weights = ef.max_sharpe()\n",
    "    return(weights)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Form Lists to Pass to Write Order #####\n",
    "\n",
    "trade_symbolist = []\n",
    "for sym in weight_dict.keys():\n",
    "    trade_symbolist.append(sym)\n",
    "\n",
    "weight_list = []\n",
    "for sym in weight_dict.keys():\n",
    "    weight_list.append(weight_dict[sym])\n",
    "\n",
    "poslist = []\n",
    "for wei in weight_list:\n",
    "    poslist.append(0)\n",
    "\n",
    "trade_token_list = [] \n",
    "for sym in trade_symbolist:\n",
    "    trade_token_list.append(instrumentLookup(sym.upper()))    \n",
    "\n",
    "ltpdict=kite.ltp(trade_token_list) #fetching end of minute price\n",
    "latest = [] #iniatiing list\n",
    "\n",
    "for token in trade_token_list:  \n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "order_index = 1\n",
    "        \n",
    "\n",
    "len(weight_list)\n",
    "equal_weight_list = []\n",
    "for i in range(len(weight_list)):\n",
    "    equal_weight_list.append(1/len(weight_list))\n",
    "\n",
    "final_weight_list = []\n",
    "for i,j in zip(weight_list,equal_weight_list):\n",
    "    final_weight_list.append((i*0.5+j*1.5)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# download the data\n",
    "j = requests.get(url=\"https://masterswift.mastertrust.co.in/api/v2/contracts.json?exchanges=NSE\")\n",
    "\n",
    "# looks to be json so let's see if json will load it\n",
    "content = json.loads(j.content)\n",
    "df = pd.DataFrame.from_dict(content['NSE'])\n",
    "\n",
    "mt_token_map = {}\n",
    "for sym,tok in zip(mt_df.trading_symbol, mt_df.code):\n",
    "    mt_token_map.update({sym:tok})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load capital avaiblabl \n",
    "id_list = ['NL0119440']\n",
    "#capital_dict = {}\n",
    "#for i in id_list:\n",
    "    #df_temp = pd.read_sql('SELECT * FROM Investor_14FD050 WHERE Date = \"2021-07-16\"', engine_cloud_investor_log)\n",
    "    #capitak.update({sym:tok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = final_weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "# getting utc timezone\n",
    "utc = pytz.utc\n",
    "# getting timezone by name\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "# getting datetime of specified timezone\n",
    "now = datetime.now(tz=ist)\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "position_dict = {}\n",
    "def write_orderr(symbol,perc,price,pos):    \n",
    "    \n",
    "    capital = 50000\n",
    "    posnew=int(capital*perc/price) \n",
    "    #print(posnew)\n",
    "    global order_index\n",
    "    global current_time\n",
    "    now = datetime.now(tz=ist)\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    position_dict.update({symbol:posnew})\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        ################\n",
    "\n",
    "        quantity=posnew-pos\n",
    "        qty=int(quantity)\n",
    "        \n",
    "        if posnew*pos>=0:\n",
    "            if qty==0:\n",
    "                pass\n",
    "            elif qty>0:\n",
    "                \n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "                \n",
    "            else:\n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "\n",
    "        elif posnew*pos<0:\n",
    "            if pos>0:\n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1\n",
    "                \n",
    "            else: \n",
    "                writer.writerow([order_index,symbol.upper() + \"-EQ\",qty,\"14FD050\",\"LIMIT\",price,current_time])\n",
    "                order_index = order_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def request_generator(token,order_side,price,quantity,client_id,auth):\n",
    "    \n",
    "    \n",
    "    url = \"https://masterswift-beta.mastertrust.co.in/api/v1/orders?exchange=NSE&instrument_token=\" +str(token)+\"&order_side=\" +str(order_side) + \"&order_type=LIMIT&price=\"+str(price)+\"&product=NRML&quantity=\"+str(quantity)+\"&validity=DAY&user_order_id=15&client_id=\" +str(client_id)\n",
    "    \n",
    "    #url = \"https://masterswift-beta.mastertrust.co.in/api/v1/orders?exchange=NSE&instrument_token=\" \\\n",
    "    #+ str(token) \"&order_side=\" # +str(order_side) + \"&order_type=LIMIT&price=\" # + str(price) + \"&product=NRML&quantity=\" + \"&validity=DAY&user_order_id=\\\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'x-device-type': 'WEB',\n",
    "      'client_id': client_id,\n",
    "      'x-authorization-token': auth\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "    print(response.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Get date for today ###########################\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Fetch auth tokens for client orders ############\n",
    "auth_token_dict = {}\n",
    "id_list =  ['NL0119440']\n",
    "df = pd.read_csv('/home/ec2-user/trading/Data/Equity Pipeline/Tokens/auth_tokens_' + str(today) + '.csv')\n",
    "for i,tk in zip(id_list,df.Token):\n",
    "    auth_token_dict.update({i:tk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiplier(idx):\n",
    "    account_dict = {'NL0119440' : 1 ,'NL0120070' : 1,'NL0120099' : 1 ,'NL01225' : 1}\n",
    "    #print(account_dict[idx])\n",
    "    return account_dict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "position_dict = {}\n",
    "\n",
    "def write_order_multi(token,perc,price,pos):    \n",
    "    \n",
    "    capital = 50000\n",
    "    global order_index\n",
    "    posnew=int(capital*perc/price) \n",
    "    position_dict.update({symbol.upper() + '-EQ':posnew})\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        ################\n",
    "\n",
    "        quantity=posnew-pos\n",
    "        qty=int(quantity)\n",
    "        \n",
    "        random.shuffle(id_list)\n",
    "\n",
    "        for idx in id_list:\n",
    "            multiplier = get_multiplier(idx)\n",
    "        \n",
    "        \n",
    "            if posnew*pos>=0:\n",
    "                if qty==0:\n",
    "                    pass\n",
    "                elif qty>0:\n",
    "                    \n",
    "                    print(token,'BUY',price,qty*get_multiplier(idx),idx,symbol)\n",
    "                    \n",
    "                    #request_generator(token,'BUY',price,qty*get_multiplier(idx),idx,auth_token_dict[idx])\n",
    "\n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else:\n",
    "                    request_generator(token,'SELL',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "                      \n",
    "\n",
    "            elif posnew*pos<0:\n",
    "                if pos>0:\n",
    "                    \n",
    "                    request_generator(token,'SELL',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1\n",
    "\n",
    "                else: \n",
    "                    \n",
    "                    \n",
    "                    request_generator(token,'BUY',price,qty*get_multiplier(idx),idx,auth_token_dict(idx))\n",
    "                    \n",
    "                    writer.writerow([order_index,symbol.upper() + \"-EQ\",qty*get_multiplier(idx),idx,\"LIMIT\",price,current_time])\n",
    "                    order_index = order_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Live Server\n",
    "def store_order():\n",
    "      \n",
    "    \n",
    "    file = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "    fil = open(file,\"r\")\n",
    "    orders = fil.read()\n",
    "    fil.close()\n",
    "    \n",
    "    wrt = open('/home/ec2-user/trading/Trade/Positions/total_orders' + str(today) + '.csv', 'a') \n",
    "    wrt.write(orders)\n",
    "    wrt.close()\n",
    "                \n",
    "    #file = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv','w+')\n",
    "    #file.close()\n",
    "    print(\"streamed :D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Re-stream cancelled order ######\n",
    "import csv\n",
    "#order_regenerator(order_index,'POWERGRID-EQ',\"14FD050\",86,219.70)\n",
    "def order_regenerator(idx, indentifier, client_id, quantity,price):\n",
    "    with open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'a', newline='') as file: \n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([idx,indentifier,quantity,client_id,\"LIMIT\",price,current_time])\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-target",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Fetch Latest State and Write and Stream Order ######\n",
    "ltpdict=kite.ltp(trade_token_list) #fetching end of minute price\n",
    "latest = [] #iniatiing list\n",
    "\n",
    "for token in trade_token_list:  \n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "for symbol,perc,price,pos in zip(trade_symbolist,weight_list,latest,poslist):\n",
    "    write_order_multi(mt_token_map[symbol.upper() + \"-EQ\"],perc,price,pos)\n",
    "\n",
    "store_order()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = order_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Parse tradefile from broker to CSV #########################\n",
    "\n",
    "def get_trade_book(client_id, auth_token):\n",
    "    \n",
    "\n",
    "    url = \"https://masterswift-beta.mastertrust.co.in/api/v1/trades?client_id=\" + str(client_id)\n",
    "\n",
    "    payload={}\n",
    "    headers = {\n",
    "      'x-device-type': 'WEB',\n",
    "      'x-authorization-token': auth_token,\n",
    "      'client_id': 'REST6'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "parameter_list = ['trade_number','trading_symbol','trade_price','trade_quantity', 'client_id', 'trade_time']\n",
    "outer_list = []\n",
    "\n",
    "for idx in id_list:\n",
    "    trade_dict = get_trade_book(idx,auth_token_dict[idx])  \n",
    "\n",
    "    for i in range(len(trade_dict['data']['trades'])):\n",
    "        inner_list = []\n",
    "        for para in parameter_list:\n",
    "            if para == 'trade_quantity':\n",
    "                if trade_dict['data']['trades'][i]['order_side'] == 'BUY':\n",
    "                    qt = trade_dict['data']['trades'][i][para]\n",
    "                    inner_list.append(qt)\n",
    "                else:\n",
    "                    qt = trade_dict['data']['trades'][i][para]\n",
    "                    inner_list.append(-qt)\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                inner_list.append(trade_dict['data']['trades'][i][para])\n",
    "        \n",
    "        outer_list.append(inner_list)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "trade_dataframe = pd.DataFrame(outer_list, columns = ['trade_number','symbol','trade_price','qty', 'client', 'trade_time'])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftplib\n",
    "\n",
    "#order_index = 1\n",
    "df = trade_dataframe\n",
    "random.shuffle(id_list)\n",
    "for clientid in id_list:\n",
    "    print(clientid)\n",
    "    client1_df = df[df.client == clientid]\n",
    "    client1_dict = {}\n",
    "\n",
    "    sub_list = list(client1_df.symbol.values)\n",
    "    for sym,qty in zip(client1_df.symbol,client1_df.qty):\n",
    "        \n",
    "        if sub_list.count(sym) == 1:\n",
    "            client1_dict.update({sym:qty})\n",
    "        else:\n",
    "            updated_qty = np.sum(client1_df[client1_df.symbol == sym].qty.values)\n",
    "            client1_dict.update({sym:updated_qty})\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Client dict\", client1_dict)\n",
    "    left_position_dict = {}\n",
    "    \n",
    "    print(get_multiplier(clientid))\n",
    "    for key in position_dict.keys():\n",
    "        try:\n",
    "            client1_dict[key.upper()]\n",
    "            \n",
    "            if client1_dict[key.upper()] != position_dict[key]*get_multiplier(clientid):\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)-client1_dict[key.upper()]})\n",
    "                \n",
    "               \n",
    "            \n",
    "        except:\n",
    "            if position_dict[key] > 0:\n",
    "                print(\"Not existing\", key,position_dict[key])\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)})#-client1_dict[key.upper()]})\n",
    "                \n",
    "            \n",
    "    print(\"Left position dict :\", left_position_dict)       \n",
    "    left_token_list = []            \n",
    "    for key in left_position_dict.keys():\n",
    "        left_token_list.append(mt_token_map[key.upper()])\n",
    "    \n",
    "    ltp_token_list = []\n",
    "    for key in left_position_dict.keys():\n",
    "        ltp_token_list.append(token_map[key.upper()])\n",
    "    \n",
    "        \n",
    "    \n",
    "    latest = [] #iniatiing list\n",
    "    \n",
    "    ltpdict=kite.ltp(ltp_token_list)\n",
    "\n",
    "    for token in ltp_token_list:  \n",
    "        latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "\n",
    "    for token,sym,lat in zip(left_token_list,left_position_dict.keys(),latest):\n",
    "        print(token,sym,lat)\n",
    "        print(token,'BUY',lat,left_position_dict[sym],clientid,auth_token_dict[clientid])\n",
    "        #request_generator(token,'BUY',lat,left_position_dict[sym],clientid,auth_token_dict[clientid])\n",
    "\n",
    "        order_regenerator(idx, sym.upper() + \"-EQ\",clientid,left_position_dict[sym],lat)\n",
    "        \n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/reorder_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'w+') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders' + str(today) + '.csv', 'a') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'w+') \n",
    "wrt.close()\n",
    "store_order()\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Store Existing Positions ###########################################\n",
    "existing_position = []\n",
    "for key in position_dict.keys():\n",
    "    existing_position.append(position_dict[key])\n",
    "\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict'+ str(today) + '.pkl','wb')\n",
    "pickle.dump(position_dict, a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_index = 1\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-07.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ SQUARING OFF #########################\n",
    "order_index = 1\n",
    "import pickle\n",
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-23.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "####### Clear Existing Positions ##########\n",
    "existing_position = []\n",
    "trade_symbolist = []\n",
    "for key in position_dict.keys():\n",
    "    existing_position.append(position_dict[key])\n",
    "    trade_symbolist.append(key.replace(\"-EQ\",\"\"))\n",
    "weight_list = np.zeros(len(existing_position))\n",
    "\n",
    "\n",
    "latest = [] #iniatiing list\n",
    "trade_token_list = [] \n",
    "\n",
    "for sym in trade_symbolist:\n",
    "    trade_token_list.append(instrumentLookup(sym.upper()))  \n",
    "#print(trade_token_list)\n",
    "ltpdict=kite.ltp(trade_token_list)    \n",
    "for token in trade_token_list:\n",
    "    #print(token)\n",
    "    latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "for symbol,perc,price,pos in zip(trade_symbolist,weight_list,latest,existing_position):\n",
    "    write_order_multi(symbol,perc,price,pos)\n",
    "####### Stream Order #######\n",
    "stream_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open('/home/ec2-user/trading/Trade/Positions/postion_dict2021-06-23.pkl','rb') ### Enter the date that needs to be squared off\n",
    "position_dict = pickle.load(a_file)\n",
    "for key in position_dict.keys():\n",
    "    position_dict.update({key:-position_dict[key]})\n",
    "\n",
    "position_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = order_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## For Squaring Off Existing Position Of Earlier Time ###################\n",
    "import ftplib\n",
    "\n",
    "# create a new FTP() instance\n",
    "session = ftplib.FTP()\n",
    "\n",
    "# connect to our FTP site\n",
    "session.connect('14.142.196.162' )\n",
    "\n",
    "# log into the FTP site\n",
    "session.login('administrator', 'Hello@123!')\n",
    "\n",
    "####### FINAL #####\n",
    "\n",
    "filename = 'JagjitTradeFile2.csv'\n",
    "\n",
    "localfile = open('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv', 'wb')\n",
    "session.retrbinary('RETR ' + filename, localfile.write, 1024)\n",
    "\n",
    "session.quit()\n",
    "localfile.close()\n",
    "\n",
    "order_index = 1\n",
    "df = pd.read_csv('/home/ec2-user/trading/Trade/Positions/trade_file' + str(today) + '.csv',names =  ['index','symbol','foo','qty','client','date','time-stamp'])\n",
    "random.shuffle(id_list)\n",
    "for clientid in id_list:\n",
    "    print(clientid)\n",
    "    client1_df = df[df.client == clientid]\n",
    "    client1_dict = {}\n",
    "\n",
    "    sub_list = list(client1_df.symbol.values)\n",
    "    for sym,qty in zip(client1_df.symbol,client1_df.qty):\n",
    "        \n",
    "        if sub_list.count(sym) == 1:\n",
    "            client1_dict.update({sym:qty})\n",
    "        else:\n",
    "            updated_qty = np.sum(client1_df[client1_df.symbol == sym].qty.values)\n",
    "            client1_dict.update({sym:updated_qty})\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"Client dict\", client1_dict)\n",
    "    left_position_dict = {}\n",
    "    \n",
    "    print(get_multiplier(clientid))\n",
    "    for key in position_dict.keys():\n",
    "        try:\n",
    "            client1_dict[key.upper()]\n",
    "            \n",
    "            if client1_dict[key.upper()] != position_dict[key]*get_multiplier(clientid):\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)-client1_dict[key.upper()]})\n",
    "                \n",
    "               \n",
    "            \n",
    "        except:\n",
    "            if position_dict[key] < 0:\n",
    "                print(\"Not existing\", key,position_dict[key])\n",
    "                left_position_dict.update({key:position_dict[key]*get_multiplier(clientid)})#-client1_dict[key.upper()]})\n",
    "                \n",
    "            \n",
    "           \n",
    "    left_token_list = []            \n",
    "    for key in left_position_dict.keys():\n",
    "        left_token_list.append(token_map[key.upper()])\n",
    "        \n",
    "    print(left_position_dict)\n",
    "    latest = [] #iniatiing list\n",
    "    try:\n",
    "        ltpdict=kite.ltp(left_token_list)\n",
    "\n",
    "        for token in left_token_list:  \n",
    "            latest.append(ltpdict[str(token)]['last_price']) \n",
    "\n",
    "\n",
    "        for sym,lat in zip(left_position_dict.keys(),latest):\n",
    "            order_regenerator(idx, sym.upper() + \"-EQ\",clientid,left_position_dict[sym],lat)\n",
    "            print(sym,lat)\n",
    "            idx = idx + 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/reorder_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/orders_stream.csv', 'w+') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "\n",
    "\n",
    "filepath = \"/home/ec2-user/trading/Trade/Positions/orders_stream.csv\"\n",
    "file = open(filepath,\"r\")\n",
    "orders = file.read()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/resent_orders' + str(today) + '.csv', 'a') \n",
    "wrt.write(orders)\n",
    "wrt.close()\n",
    "wrt = open('/home/ec2-user/trading/Trade/Positions/reorder_stream.csv', 'w+') \n",
    "wrt.close()\n",
    "stream_order()\n",
    "%time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
